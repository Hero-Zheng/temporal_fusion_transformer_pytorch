{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T03:09:20.062715Z",
     "start_time": "2020-04-22T03:09:18.795699Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from data.data_download import Config, download_electricity\n",
    "from data_formatters.electricity import ElectricityFormatter\n",
    "from data_formatters.base import DataTypes, InputTypes\n",
    "\n",
    "from data.custom_dataset import TFTDataset\n",
    "from models import GatedLinearUnit\n",
    "from models import GateAddNormNetwork\n",
    "from models import GatedResidualNetwork \n",
    "from models import ScaledDotProductAttention\n",
    "from models import InterpretableMultiHeadAttention\n",
    "from models import VariableSelectionNetwork\n",
    "\n",
    "from quantile_loss import QuantileLossCalculator\n",
    "from quantile_loss import NormalizedQuantileLossCalculator\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from argparse import ArgumentParser\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T16:47:54.934322Z",
     "start_time": "2020-03-09T16:47:54.932271Z"
    }
   },
   "outputs": [],
   "source": [
    "config = Config('data','data/electricity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T16:52:20.011881Z",
     "start_time": "2020-03-09T16:47:57.762444Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulling data from https://archive.ics.uci.edu/ml/machine-learning-databases/00321/LD2011_2014.txt.zip to data/LD2011_2014.txt.zip\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3369123/1878696367.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdownload_electricity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/temporal_fusion_transformer_pytorch/data/data_download.py\u001b[0m in \u001b[0;36mdownload_electricity\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mzip_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.zip'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mdownload_and_unzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsv_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Aggregating to hourly data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/temporal_fusion_transformer_pytorch/data/data_download.py\u001b[0m in \u001b[0;36mdownload_and_unzip\u001b[0;34m(url, zip_path, csv_path, data_folder)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \"\"\"\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mdownload_from_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0munzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsv_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/temporal_fusion_transformer_pytorch/data/data_download.py\u001b[0m in \u001b[0;36mdownload_from_url\u001b[0;34m(url, output_path)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Pulling data from {} to {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mwget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'done'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tft37/lib/python3.7/site-packages/wget.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(url, out, bar)\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0mbinurl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0mtmpfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mulib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinurl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmpfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect_filename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutdir\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tft37/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m                 \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tft37/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    463\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tft37/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_readinto_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tft37/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_readinto_chunked\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m                 \u001b[0mchunk_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_chunk_left\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mchunk_left\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtotal_bytes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tft37/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_get_chunk_left\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    560\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_safe_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# toss the CRLF at the end of the chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m                 \u001b[0mchunk_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_next_chunk_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tft37/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_read_next_chunk_size\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_next_chunk_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m         \u001b[0;31m# Read the next chunk size from the file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"chunk size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tft37/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tft37/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1069\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1071\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tft37/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "download_electricity(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T03:09:29.304537Z",
     "start_time": "2020-04-22T03:09:20.960449Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/electricity.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3369123/1130707111.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0melectricity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/electricity.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata_formatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mElectricityFormatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melectricity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tft37/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tft37/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tft37/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tft37/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tft37/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tft37/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tft37/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tft37/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/electricity.csv'"
     ]
    }
   ],
   "source": [
    "electricity = pd.read_csv('data/electricity.csv', index_col = 0)\n",
    "data_formatter = ElectricityFormatter()\n",
    "train, valid, test = data_formatter.split_data(electricity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T02:56:55.662935Z",
     "start_time": "2020-04-22T02:56:55.659314Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“tft37”的单元格需要ipykernel包。\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tft37 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "train.shape, valid.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T02:56:55.700490Z",
     "start_time": "2020-04-22T02:56:55.664219Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“tft37”的单元格需要ipykernel包。\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tft37 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "train.days_from_start.value_counts().to_frame().reset_index().sort_values(by=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T02:56:55.714718Z",
     "start_time": "2020-04-22T02:56:55.702319Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“tft37”的单元格需要ipykernel包。\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tft37 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "valid.days_from_start.value_counts().to_frame().reset_index().sort_values(by=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T02:56:55.725026Z",
     "start_time": "2020-04-22T02:56:55.715893Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“tft37”的单元格需要ipykernel包。\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tft37 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "test.days_from_start.value_counts().to_frame().reset_index().sort_values(by=['index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviewing Test dataset error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T01:17:20.633823Z",
     "start_time": "2020-03-29T01:17:20.591206Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“tft37”的单元格需要ipykernel包。\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tft37 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "test = test.reset_index(drop=True)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T01:17:21.707585Z",
     "start_time": "2020-03-29T01:17:21.674517Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“tft37”的单元格需要ipykernel包。\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tft37 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "test[test.categorical_id == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T01:20:33.732401Z",
     "start_time": "2020-03-29T01:20:33.704106Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“tft37”的单元格需要ipykernel包。\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tft37 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "test.groupby(['categorical_id']).apply(lambda x: x.shape[0]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T01:17:23.049046Z",
     "start_time": "2020-03-29T01:17:23.042974Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“tft37”的单元格需要ipykernel包。\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tft37 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "g = test.groupby(['categorical_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T01:17:23.496912Z",
     "start_time": "2020-03-29T01:17:23.492365Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“tft37”的单元格需要ipykernel包。\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tft37 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "data_formatter.get_time_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T01:17:24.633923Z",
     "start_time": "2020-03-29T01:17:24.102559Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“tft37”的单元格需要ipykernel包。\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tft37 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "df_index_abs = g[['categorical_id']].transform(lambda x: x.index+data_formatter.get_time_steps()) \\\n",
    "                        .reset_index() \\\n",
    "                        .rename(columns={'index':'init_abs',\n",
    "                                         'categorical_id':'end_abs'})\n",
    "df_index_abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T01:17:25.227946Z",
     "start_time": "2020-03-29T01:17:24.829277Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“tft37”的单元格需要ipykernel包。\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tft37 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "df_index_rel_init = g[['categorical_id']].transform(lambda x: x.reset_index(drop=True).index) \\\n",
    "                        .rename(columns={'categorical_id':'init_rel'})\n",
    "df_index_rel_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T01:17:25.741907Z",
     "start_time": "2020-03-29T01:17:25.283520Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“tft37”的单元格需要ipykernel包。\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tft37 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "df_index_rel_end = g[['categorical_id']].transform(lambda x: x.reset_index(drop=True).index+data_formatter.get_time_steps()) \\\n",
    "                .rename(columns={'categorical_id':'end_rel'})\n",
    "df_index_rel_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T01:17:26.025561Z",
     "start_time": "2020-03-29T01:17:26.019175Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“tft37”的单元格需要ipykernel包。\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tft37 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "336 - 192 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T01:17:27.362184Z",
     "start_time": "2020-03-29T01:17:27.050941Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“tft37”的单元格需要ipykernel包。\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tft37 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "df_total_count = g[['categorical_id']].transform(lambda x: x.shape[0] - data_formatter.get_time_steps() + 1) \\\n",
    "                .rename(columns = {'categorical_id':'group_count'})\n",
    "df_total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T01:17:28.518757Z",
     "start_time": "2020-03-29T01:17:28.484203Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“tft37”的单元格需要ipykernel包。\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tft37 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "new_test = pd.concat([df_index_abs, \n",
    "                       df_index_rel_init,\n",
    "                       df_index_rel_end,\n",
    "                       test[['id']], \n",
    "                       df_total_count], axis = 1).reset_index(drop = True)\n",
    "new_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T01:22:25.641796Z",
     "start_time": "2020-03-29T01:22:25.602541Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“tft37”的单元格需要ipykernel包。\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tft37 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "new_test[new_test.end_rel < test.groupby(['categorical_id']).apply(lambda x: x.shape[0]).mean()].reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T03:09:35.347675Z",
     "start_time": "2020-04-22T03:09:29.305754Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“tft37”的单元格需要ipykernel包。\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tft37 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "train_dataset = TFTDataset(train)\n",
    "valid_dataset = TFTDataset(valid)\n",
    "test_dataset = TFTDataset(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T02:57:13.230902Z",
     "start_time": "2020-04-22T02:57:13.227547Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“tft37”的单元格需要ipykernel包。\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tft37 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "len(train_dataset), len(valid_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T02:57:13.238349Z",
     "start_time": "2020-04-22T02:57:13.232842Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“tft37”的单元格需要ipykernel包。\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tft37 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "len(train_dataset), len(valid_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T02:57:13.252589Z",
     "start_time": "2020-04-22T02:57:13.239632Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“tft37”的单元格需要ipykernel包。\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tft37 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "test_dataset[0][0].shape, test_dataset[0][1].shape, test_dataset[0][2].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal Fusion Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T03:09:35.415971Z",
     "start_time": "2020-04-22T03:09:35.349298Z"
    },
    "code_folding": [
     1,
     98,
     114,
     134,
     144,
     153,
     174,
     188,
     196,
     202,
     207,
     217,
     226,
     242,
     301,
     446,
     449,
     452,
     467,
     478,
     483,
     491,
     497,
     526
    ]
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“tft37”的单元格需要ipykernel包。\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tft37 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "class TemporalFusionTransformer(pl.LightningModule):\n",
    "    def __init__(self, hparams):\n",
    "        super(TemporalFusionTransformer, self).__init__()\n",
    "        \n",
    "        self.hparams = hparams\n",
    "        \n",
    "        self.name = self.__class__.__name__\n",
    "\n",
    "        # Data parameters\n",
    "        self.time_steps = int(hparams.total_time_steps)#int(params['total_time_steps'])\n",
    "        self.input_size = int(hparams.input_size)#int(params['input_size'])\n",
    "        self.output_size = int(hparams.output_size)#int(params['output_size'])\n",
    "        self.category_counts = json.loads(str(hparams.category_counts))#json.loads(str(params['category_counts']))\n",
    "        self.num_categorical_variables = len(self.category_counts)\n",
    "        self.num_regular_variables = self.input_size - self.num_categorical_variables\n",
    "        self.n_multiprocessing_workers = int(hparams.multiprocessing_workers) #int(params['multiprocessing_workers'])\n",
    "\n",
    "        # Relevant indices for TFT\n",
    "        self._input_obs_loc = json.loads(str(hparams.input_obs_loc))#json.loads(str(params['input_obs_loc']))\n",
    "        self._static_input_loc = json.loads(str(hparams.static_input_loc))#json.loads(str(params['static_input_loc']))\n",
    "        self._known_regular_input_idx = json.loads(str(hparams.known_regular_inputs))#json.loads(str(params['known_regular_inputs']))\n",
    "        self._known_categorical_input_idx = json.loads(str(hparams.known_categorical_inputs))#json.loads(str(params['known_categorical_inputs']))\n",
    "        \n",
    "        self.num_non_static_historical_inputs = self.get_historical_num_inputs()\n",
    "        self.num_non_static_future_inputs = self.get_future_num_inputs()\n",
    "        \n",
    "        self.column_definition = [\n",
    "                                  ('id', DataTypes.REAL_VALUED, InputTypes.ID),\n",
    "                                  ('hours_from_start', DataTypes.REAL_VALUED, InputTypes.TIME),\n",
    "                                  ('power_usage', DataTypes.REAL_VALUED, InputTypes.TARGET),\n",
    "                                  ('hour', DataTypes.REAL_VALUED, InputTypes.KNOWN_INPUT),\n",
    "                                  ('day_of_week', DataTypes.REAL_VALUED, InputTypes.KNOWN_INPUT),\n",
    "                                  ('hours_from_start', DataTypes.REAL_VALUED, InputTypes.KNOWN_INPUT),\n",
    "                                  ('categorical_id', DataTypes.CATEGORICAL, InputTypes.STATIC_INPUT),\n",
    "                                ]\n",
    "\n",
    "        # Network params\n",
    "        self.quantiles = [0.1, 0.5, 0.9]\n",
    "#         self.use_cudnn = use_cudnn  # Whether to use GPU optimised LSTM\n",
    "        self.hidden_layer_size = int(hparams.hidden_layer_size)#int(params['hidden_layer_size'])\n",
    "        self.dropout_rate = float(hparams.dropout_rate)#float(params['dropout_rate'])\n",
    "        self.max_gradient_norm = float(hparams.max_gradient_norm)#float(params['max_gradient_norm'])\n",
    "        self.learning_rate = float(hparams.learning_rate)#float(params['learning_rate'])\n",
    "        self.minibatch_size = int(hparams.minibatch_size)#int(params['minibatch_size'])\n",
    "        self.num_epochs = int(hparams.num_epochs)#int(params['num_epochs'])\n",
    "        self.early_stopping_patience = int(hparams.early_stopping_patience)#int(params['early_stopping_patience'])\n",
    "\n",
    "        self.num_encoder_steps = int(hparams.num_encoder_steps)#int(params['num_encoder_steps'])\n",
    "        self.num_stacks = int(hparams.stack_size)#int(params['stack_size'])\n",
    "        self.num_heads = int(hparams.num_heads)#int(params['num_heads'])\n",
    "\n",
    "        # Serialisation options\n",
    "#         self._temp_folder = os.path.join(params['model_folder'], 'tmp')\n",
    "#         self.reset_temp_folder()\n",
    "\n",
    "        # Extra components to store Tensorflow nodes for attention computations\n",
    "        self._input_placeholder = None\n",
    "        self._attention_components = None\n",
    "        self._prediction_parts = None\n",
    "\n",
    "        print('*** {} params ***'.format(self.name))\n",
    "        for k in vars(hparams):\n",
    "            print('# {} = {}'.format(k, vars(hparams)[k]))\n",
    "            \n",
    "        self.train_criterion = QuantileLossCalculator(self.quantiles, self.output_size)\n",
    "        self.test_criterion = NormalizedQuantileLossCalculator(self.quantiles, self.output_size)\n",
    "\n",
    "        # Build model\n",
    "        ## Build embeddings\n",
    "        self.build_embeddings()\n",
    "        \n",
    "        ## Build Static Contex Networks\n",
    "        self.build_static_context_networks()\n",
    "        \n",
    "        ## Building Variable Selection Networks\n",
    "        self.build_variable_selection_networks()\n",
    "        \n",
    "        ## Build Lstm\n",
    "        self.build_lstm()\n",
    "        \n",
    "        ## Build GLU for after lstm encoder decoder and layernorm\n",
    "        self.build_post_lstm_gate_add_norm()\n",
    "        \n",
    "        ## Build Static Enrichment Layer\n",
    "        self.build_static_enrichment()\n",
    "        \n",
    "        ## Building decoder multihead attention\n",
    "        self.build_temporal_self_attention()\n",
    "        \n",
    "        ## Building positionwise decoder\n",
    "        self.build_position_wise_feed_forward()\n",
    "        \n",
    "        ## Build output feed forward\n",
    "        self.build_output_feed_forward()\n",
    "        \n",
    "        ## Initializing remaining weights\n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        for name, p in self.named_parameters():\n",
    "            if ('lstm' in name and 'ih' in name) and 'bias' not in name:\n",
    "                #print(name)\n",
    "                #print(p.shape)\n",
    "                torch.nn.init.xavier_uniform_(p)\n",
    "#                 torch.nn.init.kaiming_normal_(p, a=0, mode='fan_in', nonlinearity='sigmoid')\n",
    "            elif ('lstm' in name and 'hh' in name) and 'bias' not in name:\n",
    "        \n",
    "                 torch.nn.init.orthogonal_(p)\n",
    "            \n",
    "            elif 'lstm' in name and 'bias' in name:\n",
    "                #print(name)\n",
    "                #print(p.shape)\n",
    "                torch.nn.init.zeros_(p)\n",
    "        \n",
    "    def get_historical_num_inputs(self):\n",
    "        \n",
    "        obs_inputs = [i for i in self._input_obs_loc]\n",
    "        \n",
    "        known_regular_inputs = [i for i in self._known_regular_input_idx\n",
    "                                if i not in self._static_input_loc]\n",
    "            \n",
    "        known_categorical_inputs = [i for i in self._known_categorical_input_idx\n",
    "                                    if i + self.num_regular_variables not in self._static_input_loc]\n",
    "        \n",
    "        wired_embeddings = [i for i in range(self.num_categorical_variables)\n",
    "                            if i not in self._known_categorical_input_idx \n",
    "                            and i not in self._input_obs_loc]\n",
    "\n",
    "        unknown_inputs = [i for i in range(self.num_regular_variables)\n",
    "                          if i not in self._known_regular_input_idx\n",
    "                          and i not in self._input_obs_loc]\n",
    "\n",
    "        return len(obs_inputs+known_regular_inputs+known_categorical_inputs+wired_embeddings+unknown_inputs)\n",
    "    \n",
    "    def get_future_num_inputs(self):\n",
    "            \n",
    "        known_regular_inputs = [i for i in self._known_regular_input_idx\n",
    "                                if i not in self._static_input_loc]\n",
    "            \n",
    "        known_categorical_inputs = [i for i in self._known_categorical_input_idx\n",
    "                                    if i + self.num_regular_variables not in self._static_input_loc]\n",
    "\n",
    "        return len(known_regular_inputs + known_categorical_inputs)\n",
    "    \n",
    "    def build_embeddings(self):\n",
    "        self.categorical_var_embeddings = nn.ModuleList([nn.Embedding(self.category_counts[i], \n",
    "                                                                      self.hidden_layer_size) \n",
    "                                                     for i in range(self.num_categorical_variables)])\n",
    "\n",
    "        self.regular_var_embeddings = nn.ModuleList([nn.Linear(1, \n",
    "                                                              self.hidden_layer_size) \n",
    "                                                  for i in range(self.num_regular_variables)])\n",
    "\n",
    "    def build_variable_selection_networks(self):\n",
    "        \n",
    "        self.static_vsn = VariableSelectionNetwork(hidden_layer_size = self.hidden_layer_size,\n",
    "                                                   input_size = self.hidden_layer_size * len(self._static_input_loc),\n",
    "                                                   output_size = len(self._static_input_loc),\n",
    "                                                   dropout_rate = self.dropout_rate)\n",
    "        \n",
    "        self.temporal_historical_vsn = VariableSelectionNetwork(hidden_layer_size = self.hidden_layer_size,\n",
    "                                                                input_size = self.hidden_layer_size *\n",
    "                                                                        self.num_non_static_historical_inputs,\n",
    "                                                                output_size = self.num_non_static_historical_inputs,\n",
    "                                                                dropout_rate = self.dropout_rate,\n",
    "                                                                additional_context=self.hidden_layer_size)\n",
    "        \n",
    "        self.temporal_future_vsn = VariableSelectionNetwork(hidden_layer_size = self.hidden_layer_size,\n",
    "                                                            input_size = self.hidden_layer_size *\n",
    "                                                                        self.num_non_static_future_inputs,\n",
    "                                                            output_size = self.num_non_static_future_inputs,\n",
    "                                                            dropout_rate = self.dropout_rate,\n",
    "                                                            additional_context=self.hidden_layer_size)\n",
    "        \n",
    "    def build_static_context_networks(self):\n",
    "        \n",
    "        self.static_context_variable_selection_grn = GatedResidualNetwork(self.hidden_layer_size,\n",
    "                                                                          dropout_rate=self.dropout_rate)\n",
    "        \n",
    "        self.static_context_enrichment_grn = GatedResidualNetwork(self.hidden_layer_size,\n",
    "                                                              dropout_rate=self.dropout_rate)\n",
    "\n",
    "        self.static_context_state_h_grn = GatedResidualNetwork(self.hidden_layer_size,\n",
    "                                                           dropout_rate=self.dropout_rate)\n",
    "        \n",
    "        self.static_context_state_c_grn = GatedResidualNetwork(self.hidden_layer_size,\n",
    "                                                           dropout_rate=self.dropout_rate)\n",
    "        \n",
    "    def build_lstm(self):\n",
    "        self.historical_lstm = nn.LSTM(input_size = self.hidden_layer_size,\n",
    "                                       hidden_size = self.hidden_layer_size,\n",
    "                                       batch_first = True)\n",
    "        self.future_lstm = nn.LSTM(input_size = self.hidden_layer_size,\n",
    "                                   hidden_size = self.hidden_layer_size,\n",
    "                                   batch_first = True)\n",
    "        \n",
    "    def build_post_lstm_gate_add_norm(self):\n",
    "        self.post_seq_encoder_gate_add_norm = GateAddNormNetwork(self.hidden_layer_size,\n",
    "                                                                 self.hidden_layer_size,\n",
    "                                                                 self.dropout_rate,\n",
    "                                                                 activation = None)\n",
    "        \n",
    "    def build_static_enrichment(self):\n",
    "        self.static_enrichment = GatedResidualNetwork(self.hidden_layer_size,\n",
    "                                                      dropout_rate = self.dropout_rate,\n",
    "                                                      additional_context=self.hidden_layer_size)\n",
    "        \n",
    "    def build_temporal_self_attention(self):\n",
    "        self.self_attn_layer = InterpretableMultiHeadAttention(n_head = self.num_heads, \n",
    "                                                               d_model = self.hidden_layer_size,\n",
    "                                                               dropout = self.dropout_rate)\n",
    "        \n",
    "        self.post_attn_gate_add_norm = GateAddNormNetwork(self.hidden_layer_size,\n",
    "                                                           self.hidden_layer_size,\n",
    "                                                           self.dropout_rate,\n",
    "                                                           activation = None)\n",
    "        \n",
    "    def build_position_wise_feed_forward(self):\n",
    "        self.GRN_positionwise = GatedResidualNetwork(self.hidden_layer_size,\n",
    "                                                     dropout_rate = self.dropout_rate)\n",
    "        \n",
    "        self.post_tfd_gate_add_norm = GateAddNormNetwork(self.hidden_layer_size,\n",
    "                                                         self.hidden_layer_size,\n",
    "                                                         self.dropout_rate,\n",
    "                                                         activation = None)\n",
    "        \n",
    "    def build_output_feed_forward(self):\n",
    "        self.output_feed_forward = torch.nn.Linear(self.hidden_layer_size, \n",
    "                                                   self.output_size * len(self.quantiles))\n",
    "         \n",
    "    def get_decoder_mask(self, self_attn_inputs):\n",
    "        \"\"\"Returns causal mask to apply for self-attention layer.\n",
    "        Args:\n",
    "        self_attn_inputs: Inputs to self attention layer to determine mask shape\n",
    "        \"\"\"\n",
    "        len_s = self_attn_inputs.shape[1]\n",
    "        bs = self_attn_inputs.shape[0]\n",
    "        mask = torch.cumsum(torch.eye(len_s), 0)\n",
    "        mask = mask.repeat(bs,1,1).to(torch.float32)\n",
    "\n",
    "        return mask.to(DEVICE)\n",
    "    \n",
    "    def get_tft_embeddings(self, regular_inputs, categorical_inputs):\n",
    "        # Static input\n",
    "        if self._static_input_loc:\n",
    "            static_regular_inputs = [self.regular_var_embeddings[i](regular_inputs[:, 0, i:i + 1]) \n",
    "                                    for i in range(self.num_regular_variables)\n",
    "                                    if i in self._static_input_loc]\n",
    "            #print('static_regular_inputs')\n",
    "            #print([print(emb.shape) for emb in static_regular_inputs])\n",
    "            \n",
    "            static_categorical_inputs = [self.categorical_var_embeddings[i](categorical_inputs[Ellipsis, i])[:,0,:] \n",
    "                                         for i in range(self.num_categorical_variables)\n",
    "                                         if i + self.num_regular_variables in self._static_input_loc]\n",
    "            #print('static_categorical_inputs')\n",
    "            #print([print(emb.shape) for emb in static_categorical_inputs])\n",
    "            static_inputs = torch.stack(static_regular_inputs + static_categorical_inputs, axis = 1)\n",
    "        else:\n",
    "            static_inputs = None\n",
    "            \n",
    "        # Target input\n",
    "        obs_inputs = torch.stack([self.regular_var_embeddings[i](regular_inputs[Ellipsis, i:i + 1])\n",
    "                                     for i in self._input_obs_loc], axis=-1)\n",
    "        \n",
    "        # Observed (a prioir unknown) inputs\n",
    "        wired_embeddings = []\n",
    "        for i in range(self.num_categorical_variables):\n",
    "            if i not in self._known_categorical_input_idx \\\n",
    "            and i not in self._input_obs_loc:\n",
    "                e = self.categorical_var_embeddings[i](categorical_inputs[:, :, i])\n",
    "                wired_embeddings.append(e)\n",
    "\n",
    "        unknown_inputs = []\n",
    "        for i in range(self.num_regular_variables):\n",
    "            if i not in self._known_regular_input_idx \\\n",
    "            and i not in self._input_obs_loc:\n",
    "                e = self.regular_var_embeddings[i](regular_inputs[Ellipsis, i:i + 1])\n",
    "                unknown_inputs.append(e)\n",
    "                \n",
    "        if unknown_inputs + wired_embeddings:\n",
    "            unknown_inputs = torch.stack(unknown_inputs + wired_embeddings, axis=-1)\n",
    "        else:\n",
    "            unknown_inputs = None\n",
    "            \n",
    "        # A priori known inputs\n",
    "        known_regular_inputs = [self.regular_var_embeddings[i](regular_inputs[Ellipsis, i:i + 1])\n",
    "                                for i in self._known_regular_input_idx\n",
    "                                if i not in self._static_input_loc]\n",
    "        #print('known_regular_inputs')\n",
    "        #print([print(emb.shape) for emb in known_regular_inputs])\n",
    "        \n",
    "        known_categorical_inputs = [self.categorical_var_embeddings[i](categorical_inputs[Ellipsis, i])\n",
    "                                    for i in self._known_categorical_input_idx\n",
    "                                    if i + self.num_regular_variables not in self._static_input_loc]\n",
    "       #print('known_categorical_inputs')\n",
    "       #print([print(emb.shape) for emb in known_categorical_inputs])\n",
    "\n",
    "        known_combined_layer = torch.stack(known_regular_inputs + known_categorical_inputs, axis=-1)\n",
    "        \n",
    "        return unknown_inputs, known_combined_layer, obs_inputs, static_inputs\n",
    "        \n",
    "    def forward(self, all_inputs):\n",
    "\n",
    "        regular_inputs = all_inputs[:, :, :self.num_regular_variables].to(torch.float)\n",
    "        #print('regular_inputs')\n",
    "        #print(regular_inputs.shape)\n",
    "        categorical_inputs = all_inputs[:, :, self.num_regular_variables:].to(torch.long)\n",
    "        #print('categorical_inputs')\n",
    "        #print(categorical_inputs.shape)\n",
    "        \n",
    "        unknown_inputs, known_combined_layer, obs_inputs, static_inputs \\\n",
    "            = self.get_tft_embeddings(regular_inputs, categorical_inputs)\n",
    "        \n",
    "        # Isolate known and observed historical inputs.\n",
    "        if unknown_inputs is not None:\n",
    "              historical_inputs = torch.cat([\n",
    "                  unknown_inputs[:, :self.num_encoder_steps, :],\n",
    "                  known_combined_layer[:, :self.num_encoder_steps, :],\n",
    "                  obs_inputs[:, :self.num_encoder_steps, :]\n",
    "              ], axis=-1)\n",
    "        else:\n",
    "              historical_inputs = torch.cat([\n",
    "                  known_combined_layer[:, :self.num_encoder_steps, :],\n",
    "                  obs_inputs[:, :self.num_encoder_steps, :]\n",
    "              ], axis=-1)\n",
    "                \n",
    "        #print('historical_inputs')\n",
    "        #print(historical_inputs.shape)\n",
    "        \n",
    "        # Isolate only known future inputs.\n",
    "        future_inputs = known_combined_layer[:, self.num_encoder_steps:, :]\n",
    "        #print('future_inputs')\n",
    "        #print(future_inputs.shape)\n",
    "              \n",
    "        #print('static_inputs')\n",
    "        #print(static_inputs.shape)\n",
    "        \n",
    "        static_encoder, sparse_weights = self.static_vsn(static_inputs)\n",
    "        \n",
    "        #print('static_encoder')\n",
    "        #print(static_encoder.shape)\n",
    "        \n",
    "        #print('sparse_weights')\n",
    "        #print(sparse_weights.shape)\n",
    "        \n",
    "        static_context_variable_selection = self.static_context_variable_selection_grn(static_encoder)\n",
    "        #print('static_context_variable_selection')\n",
    "        #print(static_context_variable_selection.shape)\n",
    "        static_context_enrichment = self.static_context_enrichment_grn(static_encoder)\n",
    "        #print('static_context_enrichment')\n",
    "        #print(static_context_enrichment.shape)\n",
    "        static_context_state_h = self.static_context_state_h_grn(static_encoder)\n",
    "        #print('static_context_state_h')\n",
    "        #print(static_context_state_h.shape)\n",
    "        static_context_state_c = self.static_context_state_c_grn(static_encoder)\n",
    "        #print('static_context_state_c')\n",
    "        #print(static_context_state_c.shape)\n",
    "        \n",
    "        historical_features, historical_flags \\\n",
    "        = self.temporal_historical_vsn((historical_inputs,\n",
    "                                        static_context_variable_selection))\n",
    "        #print('historical_features')\n",
    "        #print(historical_features.shape)\n",
    "        #print('historical_flags')\n",
    "        #print(historical_flags.shape)\n",
    "        \n",
    "        future_features, future_flags \\\n",
    "        = self.temporal_future_vsn((future_inputs,\n",
    "                                    static_context_variable_selection))\n",
    "        #print('future_features')\n",
    "        #print(future_features.shape)\n",
    "        #print('future_flags')\n",
    "        #print(future_flags.shape)\n",
    "        \n",
    "        history_lstm, (state_h, state_c) \\\n",
    "        = self.historical_lstm(historical_features,\n",
    "                               (static_context_state_h.unsqueeze(0),\n",
    "                                static_context_state_c.unsqueeze(0)))\n",
    "        #print('history_lstm')\n",
    "        #print(history_lstm.shape)\n",
    "        #print('state_h')\n",
    "        #print(state_h.shape)\n",
    "        #print('state_c')\n",
    "        #print(state_c.shape)\n",
    "        \n",
    "        future_lstm, _ = self.future_lstm(future_features,\n",
    "                                          (state_h,\n",
    "                                           state_c))\n",
    "        #print('future_lstm')\n",
    "        #print(future_lstm.shape)\n",
    "        \n",
    "        # Apply gated skip connection\n",
    "        input_embeddings = torch.cat((historical_features, future_features), axis=1)\n",
    "        #print('input_embeddings')\n",
    "        #print(input_embeddings.shape) \n",
    "        \n",
    "        lstm_layer = torch.cat((history_lstm, future_lstm), axis=1)\n",
    "        #print('lstm_layer')\n",
    "        #print(lstm_layer.shape) \n",
    "        \n",
    "        temporal_feature_layer = self.post_seq_encoder_gate_add_norm(lstm_layer, input_embeddings)\n",
    "        #print('temporal_feature_layer')\n",
    "        #print(temporal_feature_layer.shape)  \n",
    "        \n",
    "        # Static enrichment layers\n",
    "        expanded_static_context = static_context_enrichment.unsqueeze(1)\n",
    "        \n",
    "        enriched = self.static_enrichment((temporal_feature_layer, expanded_static_context))\n",
    "        #print('enriched')\n",
    "        #print(enriched.shape)    \n",
    "        \n",
    "        # Decoder self attention\n",
    "        #self.mask = self.get_decoder_mask(enriched)\n",
    "        #print('enriched')\n",
    "        #print(enriched.shape)\n",
    "        x, self_att = self.self_attn_layer(enriched, \n",
    "                                           enriched, \n",
    "                                           enriched,\n",
    "                                           mask = self.get_decoder_mask(enriched))\n",
    "        #print('x')\n",
    "        #print(x.shape)\n",
    "        #print('self_att')\n",
    "        #print(self_att.shape)\n",
    "        \n",
    "        x = self.post_attn_gate_add_norm(x, enriched)\n",
    "        #print('x')\n",
    "        #print(x.shape)\n",
    "        \n",
    "        # Nonlinear processing on outputs\n",
    "        decoder = self.GRN_positionwise(x)\n",
    "        #print('decoder')\n",
    "        #print(decoder.shape)\n",
    "        \n",
    "        # Final skip connection\n",
    "        transformer_layer = self.post_tfd_gate_add_norm(decoder, temporal_feature_layer)\n",
    "        #print('transformer_layer')\n",
    "        #print(transformer_layer.shape)\n",
    "        \n",
    "        outputs = self.output_feed_forward(transformer_layer[Ellipsis, self.num_encoder_steps:, :])\n",
    "        #print('outputs')\n",
    "        #print(outputs.shape)\n",
    "        \n",
    "        #ipdb.set_trace()\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "    def loss(self, y_hat, y):\n",
    "        return self.train_criterion.apply(y_hat, y)\n",
    "    \n",
    "    def test_loss(self, y_hat, y):\n",
    "        return self.test_criterion.apply(y_hat, y, self.quantiles[1])\n",
    "    \n",
    "    def training_step(self, batch, batch_nb):\n",
    "        x, y, _ = batch\n",
    "        \n",
    "        x = x.to(torch.float)\n",
    "        y = y.to(torch.float)\n",
    "#         print('y')\n",
    "#         print(y.shape)\n",
    "        y_hat = self.forward(x)\n",
    "#         print('y_hat')\n",
    "#         print(y_hat.shape)\n",
    "        loss = self.loss(y_hat, torch.cat([y, y, y], dim = -1))\n",
    "        #print(loss.shape)\n",
    "        tensorboard_logs = {'train_loss': loss}\n",
    "        return {'loss': loss, 'log': tensorboard_logs}\n",
    "    \n",
    "    def validation_step(self, batch, batch_nb):\n",
    "        x, y, _ = batch\n",
    "        x = x.to(torch.float)\n",
    "        y = y.to(torch.float)\n",
    "        y_hat = self.forward(x)\n",
    "        #print(y_hat.shape)\n",
    "        #print(torch.cat([y, y, y], dim = -1).shape)\n",
    "        loss = self.loss(y_hat, torch.cat([y, y, y], dim = -1))\n",
    "        #print(loss)\n",
    "        return {'val_loss': loss}\n",
    "    \n",
    "    def validation_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        tensorboard_logs = {'val_loss': avg_loss}\n",
    "        return {'avg_val_loss': avg_loss, 'log': tensorboard_logs}\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # OPTIONAL\n",
    "        x, y, _ = batch\n",
    "        x = x.to(torch.float)\n",
    "        y = y.to(torch.float)\n",
    "        y_hat = self.forward(x)\n",
    "        return {'test_loss': self.test_loss(y_hat[Ellipsis, 1], y[Ellipsis, 0])}\n",
    "\n",
    "    def test_end(self, outputs):\n",
    "        # OPTIONAL\n",
    "        avg_loss = torch.stack([x['test_loss'] for x in outputs]).mean()\n",
    "        tensorboard_logs = {'test_loss': avg_loss}\n",
    "        return {'avg_test_loss': avg_loss, 'log': tensorboard_logs}\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        # REQUIRED\n",
    "        # can return multiple optimizers and learning_rate schedulers\n",
    "        # (LBFGS it is automatically supported, no need for closure function)\n",
    "        return [torch.optim.Adam(self.parameters(), lr=self.learning_rate)]\n",
    "    \n",
    "    def plot_grad_flow(self, named_parameters):\n",
    "        ave_grads = []\n",
    "        layers = []\n",
    "        for name, p in named_parameters:\n",
    "            if p.grad is not None:\n",
    "                if (p.requires_grad) and (\"bias\" not in name):\n",
    "                    layers.append(name)\n",
    "                    ave_grads.append(p.grad.abs().mean())\n",
    "                    self.logger.experiment.add_histogram(tag=name, values=p.grad,\n",
    "                                                         global_step=self.trainer.global_step)\n",
    "            else:\n",
    "                 print('{} - {}'.format(name, p.requires_grad))\n",
    "            \n",
    "        # plt.plot(ave_grads, alpha=0.3, color=\"b\")\n",
    "        # plt.hlines(0, 0, len(ave_grads), linewidth=1, color=\"k\" )\n",
    "        # plt.xticks(list(range(0,len(ave_grads), 1)), layers, rotation='vertical')\n",
    "        # plt.xlim(left=0, right=len(ave_grads))\n",
    "        # plt.xlabel(\"Layers\")\n",
    "        # plt.ylabel(\"average gradient\")\n",
    "        # plt.title(\"Gradient flow\")\n",
    "        # plt.grid(True)\n",
    "        # plt.rcParams[\"figure.figsize\"] = (20, 5)\n",
    "    \n",
    "    def on_after_backward(self):\n",
    "        # example to inspect gradient information in tensorboard\n",
    "        if self.trainer.global_step % 25 == 0:  \n",
    "            self.plot_grad_flow(self.named_parameters())\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        # REQUIRED\n",
    "        return DataLoader(train_dataset, batch_size = self.minibatch_size, shuffle=True, drop_last=True, num_workers=1)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        # OPTIONAL\n",
    "        return DataLoader(valid_dataset, batch_size = self.minibatch_size, shuffle=True, drop_last=True, num_workers=1)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        # OPTIONAL\n",
    "        return DataLoader(test_dataset, batch_size = self.minibatch_size, shuffle=True, drop_last=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T03:09:35.443503Z",
     "start_time": "2020-04-22T03:09:35.417309Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“tft37”的单元格需要ipykernel包。\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tft37 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda: 0\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T03:09:35.450301Z",
     "start_time": "2020-04-22T03:09:35.445130Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“tft37”的单元格需要ipykernel包。\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tft37 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "params = data_formatter.get_experiment_params()\n",
    "params.update(data_formatter.get_default_model_params())\n",
    "\n",
    "parser = ArgumentParser(add_help=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T03:09:35.455442Z",
     "start_time": "2020-04-22T03:09:35.451554Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“tft37”的单元格需要ipykernel包。\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tft37 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "for k in params:\n",
    "    if type(params[k]) in [int, float]:\n",
    "        #if k == 'minibatch_size':\n",
    "        #    parser.add_argument('--{}'.format(k), type=type(params[k]), default = 256)\n",
    "        #else:\n",
    "        parser.add_argument('--{}'.format(k), type=type(params[k]), default = params[k])\n",
    "    else:\n",
    "        parser.add_argument('--{}'.format(k), type=str, default = str(params[k]))\n",
    "hparams = parser.parse_known_args()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T03:09:35.947089Z",
     "start_time": "2020-04-22T03:09:35.903770Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“tft37”的单元格需要ipykernel包。\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tft37 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "tft = TemporalFusionTransformer(hparams)#.to(DEVICE)\n",
    "tft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T03:09:37.696931Z",
     "start_time": "2020-04-22T03:09:37.694439Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“tft37”的单元格需要ipykernel包。\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tft37 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "early_stop_callback = EarlyStopping(monitor = 'val_loss',\n",
    "                                    min_delta = 1e-4,\n",
    "                                    patience = tft.early_stopping_patience,\n",
    "                                    verbose=False,\n",
    "                                    mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-04-22T03:09:48.709Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“tft37”的单元格需要ipykernel包。\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tft37 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_nb_epochs = tft.num_epochs,\n",
    "                     gpus = 1, \n",
    "                     track_grad_norm = 2, \n",
    "                     gradient_clip_val = tft.max_gradient_norm,\n",
    "                     early_stop_callback = early_stop_callback,\n",
    "                     #train_percent_check = 0.01,\n",
    "                     #val_percent_check = 0.01,\n",
    "                     #test_percent_check = 0.01,\n",
    "                     overfit_pct=0.01,\n",
    "                     #fast_dev_run=True,\n",
    "                     profiler=True,\n",
    "                     #print_nan_grads = True,\n",
    "                     #distributed_backend='dp'\n",
    "                    )    \n",
    "trainer.fit(tft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-04-22T03:10:15.247Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“tft37”的单元格需要ipykernel包。\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tft37 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T22:13:11.878369Z",
     "start_time": "2020-03-29T22:13:11.376438Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“tft37”的单元格需要ipykernel包。\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tft37 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T23:01:53.459938Z",
     "start_time": "2020-03-29T23:01:53.362912Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“tft37”的单元格需要ipykernel包。\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tft37 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "model = tft.load_from_metrics(\n",
    "                             weights_path='lightning_logs/version_18/checkpoints/epoch=6.ckpt',\n",
    "                             tags_csv='lightning_logs/version_18/meta_tags.csv',\n",
    "                             #on_gpu=True,\n",
    "                             map_location=None\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T23:02:02.935152Z",
     "start_time": "2020-03-29T23:02:02.932563Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“tft37”的单元格需要ipykernel包。\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tft37 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "q_risk = NormalizedQuantileLossCalculator([0.1, 0.5, 0.9], 1)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = 64, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T23:02:10.945537Z",
     "start_time": "2020-03-29T23:02:04.985297Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“tft37”的单元格需要ipykernel包。\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tft37 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "loss = []\n",
    "batches = 0\n",
    "for i, (batch, target, _ )in enumerate(test_dataloader):\n",
    "    if i < 5:\n",
    "        t = target\n",
    "        batches += 1\n",
    "        output = tft(batch)\n",
    "        loss.append(q_risk.apply(output[Ellipsis, 1], target[Ellipsis, 0], 0.5))\n",
    "    else:\n",
    "        break\n",
    "mean_loss = sum(loss) / batches\n",
    "mean_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T22:57:40.648319Z",
     "start_time": "2020-03-29T22:57:40.642766Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“tft37”的单元格需要ipykernel包。\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tft37 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T22:57:17.348076Z",
     "start_time": "2020-03-29T22:57:17.344899Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“tft37”的单元格需要ipykernel包。\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tft37 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "output[Ellipsis, 1:2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T22:55:27.672365Z",
     "start_time": "2020-03-29T22:55:27.669081Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“tft37”的单元格需要ipykernel包。\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tft37 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "t.shape, output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T16:18:34.676782Z",
     "start_time": "2020-03-26T16:18:34.667335Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“tft37”的单元格需要ipykernel包。\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tft37 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def get_decoder_mask(self_attn_inputs):\n",
    "    \"\"\"Returns causal mask to apply for self-attention layer.\n",
    "    Args:\n",
    "    self_attn_inputs: Inputs to self attention layer to determine mask shape\n",
    "    \"\"\"\n",
    "    len_s = self_attn_inputs.shape[1]\n",
    "    bs = self_attn_inputs.shape[0]\n",
    "    mask = torch.cumsum(torch.eye(len_s), 0)\n",
    "    mask = mask.repeat(bs,1,1).to(torch.float32)\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T16:20:27.615226Z",
     "start_time": "2020-03-26T16:20:27.609822Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“tft37”的单元格需要ipykernel包。\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tft37 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "a = torch.randn((2,6,4))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T16:20:27.956883Z",
     "start_time": "2020-03-26T16:20:27.942930Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“tft37”的单元格需要ipykernel包。\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tft37 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "mask = get_decoder_mask(a)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T16:18:37.428095Z",
     "start_time": "2020-03-26T16:18:37.420599Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“tft37”的单元格需要ipykernel包。\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tft37 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T16:18:37.783682Z",
     "start_time": "2020-03-26T16:18:37.778133Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“tft37”的单元格需要ipykernel包。\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tft37 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "linear = nn.Linear(4, 2, bias = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T16:18:38.026534Z",
     "start_time": "2020-03-26T16:18:38.018281Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“tft37”的单元格需要ipykernel包。\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tft37 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "a_lin = linear(a)\n",
    "a_lin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T16:43:34.121081Z",
     "start_time": "2020-03-26T16:43:34.116672Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“tft37”的单元格需要ipykernel包。\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tft37 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "to_attn = torch.bmm(a_lin, a_lin.permute(0,2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T16:44:27.955457Z",
     "start_time": "2020-03-26T16:44:27.938023Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“tft37”的单元格需要ipykernel包。\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tft37 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "masked_attn = to_attn.masked_fill(mask == 0, -1e9)\n",
    "masked_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T16:53:56.737081Z",
     "start_time": "2020-03-26T16:53:56.734449Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“tft37”的单元格需要ipykernel包。\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tft37 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T16:57:44.273261Z",
     "start_time": "2020-03-26T16:57:44.266922Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“tft37”的单元格需要ipykernel包。\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tft37 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "sft_attn = softmax(masked_attn)\n",
    "sft_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T16:58:14.286401Z",
     "start_time": "2020-03-26T16:58:14.275870Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“tft37”的单元格需要ipykernel包。\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tft37 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "torch.bmm(sft_attn, a_lin).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T16:18:41.373265Z",
     "start_time": "2020-03-26T16:18:41.366287Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“tft37”的单元格需要ipykernel包。\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tft37 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "scaled_att = ScaledDotProductAttention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T16:18:41.691534Z",
     "start_time": "2020-03-26T16:18:41.679174Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“tft37”的单元格需要ipykernel包。\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tft37 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "scaled_att(a_lin, a_lin, a_lin, mask = get_decoder_mask(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“tft37”的单元格需要ipykernel包。\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n tft37 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt1120",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "309px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
